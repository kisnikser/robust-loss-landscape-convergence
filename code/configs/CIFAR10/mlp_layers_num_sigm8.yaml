model:
  class: mlp
  input_channels: 3
  input_sizes: [32, 32]
  hidden: 128
  layers_num: 10
  variable_param: layers_num
  variable_param_grid: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
  classes: 10

logging:
  models_checkpoint_path: checkpoints/change_layers_num
  savefig_path: 'results/CIFAR10/mlp_layers_num_sigm8.png'

dataset:
  name: 'CIFAR10'
  load_path: 'data/'
  transform_params:
    mean: [0.5, 0.5, 0.5]
    std: [0.5, 0.5, 0.5]
  batch_size: 64
  size: -1

train_params:
  optimizer: Adam
  learning_rate: 3.0e-4
  num_epochs: 50

device: 'cuda'

delta_vis_params:
  mode: random-subspace-proj
  mode_params:
    estim_func: abs
    sigma: 8
    dim: 2
  num_samples: 64

visualize:
  smooth_window: 10
  train_loss_smooth_window: 20
